{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T11:45:21.513364Z",
     "start_time": "2023-12-28T11:45:15.164252Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Skip the first line\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m9\u001B[39m\u001B[38;5;241m*\u001B[39mlines_to_read\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 12\u001B[0m         \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;66;03m# Read specified number of lines\u001B[39;00m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(lines_to_read):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = 'dblp_v12.json'\n",
    "lines_to_read = 100000\n",
    "\n",
    "data_list = []  # List to hold data from lines\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Skip the first line\n",
    "    for ind in range(9*lines_to_read+1):\n",
    "        next(file)\n",
    "    \n",
    "    # Read specified number of lines\n",
    "    for _ in range(lines_to_read):\n",
    "        line = next(file)\n",
    "        # print(\"===========\")\n",
    "        # print(line)\n",
    "        if line != '}\\n':  # Ensure it's not the last line (end of JSON object)\n",
    "            if line[0]==\",\":\n",
    "                paper_dict = json.loads(line[1:])\n",
    "            else:\n",
    "                paper_dict = json.loads(line)\n",
    "            # print(\"**********\")\n",
    "            # print(line)\n",
    "            # paper_dict = json.loads(line)\n",
    "            # print(\"loaded\")\n",
    "            data_list.append(paper_dict)\n",
    "        else:\n",
    "            break  # Break loop if it's the last line\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Output DataFrame to CSV file\n",
    "output_csv_path = 'output10.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Print DataFrame (optional)\n",
    "# print(df)\n",
    "\n",
    "print(f\"CSV file '{output_csv_path}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to hold individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file\n",
    "for i in range(1, 11):  # Assuming files are named 'output1.csv' to 'output10.csv'\n",
    "    file_path = f'output{i}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "output_csv_path = 'output_entire.csv'\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file '{output_csv_path}' has been created.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-28T11:45:21.512148Z"
    }
   },
   "id": "cb7286e8eef2bd8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to hold individual DataFrames\n",
    "features = [\"id\",\"authors\",\"title\",\"year\",\"n_citation\",\"doc_type\",\"references\",\"fos\",\"venue\"]\n",
    "\n",
    "# Loop through each CSV file\n",
    "file_path = f'output1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[features]\n",
    "df = df.iloc[:5,:]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-28T11:45:21.516171Z"
    }
   },
   "id": "453b2b50a4b25a83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# paper node attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f134a73207f85d07"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/613467824.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[\"year\"]=df_new[\"year\"].astype(int)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/613467824.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[\"n_citation\"]=df_new[\"n_citation\"].astype(int)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/613467824.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[\"id\"]=\"paper\"+df_new[\"id\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# file_path = f'output_entire.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "# features = [\"id\",\"authors\",\"title\",\"year\",\"n_citation\",\"doc_type\",\"references\",\"fos\",\"venue\"]\n",
    "# df=df[features]\n",
    "# print(df.shape)\n",
    "# df.dropna(how='any', inplace=True)\n",
    "# df.to_csv(output_csv_path, index=False)\n",
    "# df.to_csv(\"output_entire_clean.csv\", index=False)\n",
    "\n",
    "file_path = f'output_entire_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_new = df[[\"id\",\"title\",\"year\",\"n_citation\",\"doc_type\"]]\n",
    "df_new[\"year\"]=df_new[\"year\"].astype(int)\n",
    "df_new[\"n_citation\"]=df_new[\"n_citation\"].astype(int)\n",
    "df_new[\"id\"]=\"paper\"+df_new[\"id\"].astype(str)\n",
    "df_new.head()\n",
    "df_new.to_csv(\"papers.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T12:16:06.674190Z",
     "start_time": "2023-12-28T12:15:54.858526Z"
    }
   },
   "id": "d605fe93a0651a00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# paper-paper edge"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d33a7099a169770"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7322280, 2)\n"
     ]
    }
   ],
   "source": [
    "file_path = f'output_entire_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_new = df[[\"id\",\"references\"]]\n",
    "df_new = df_new.dropna().reset_index(drop = True)\n",
    "\n",
    "import ast\n",
    "df_new['references'] = df_new['references'].apply(ast.literal_eval)\n",
    "df_new = df_new.explode(\"references\").reset_index(drop = True)\n",
    "\n",
    "df_new = df_new.explode(\"references\")\n",
    "df_new[\"id\"] = \"paper\" + df_new[\"id\"].astype(str)\n",
    "df_new[\"references\"] = \"paper\" + df_new[\"references\"].astype(str)\n",
    "print(df_new.shape)\n",
    "df_new.to_csv(\"paper_paper.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T03:01:25.369778Z",
     "start_time": "2024-01-02T03:00:39.360387Z"
    }
   },
   "id": "c93aa37191f76761"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# paper_author edge and author node attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdc85f841d39ce6b"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/1114433751.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['authors'] = df_new['authors'].apply(ast.literal_eval)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2033988, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "          id       author_name          author_org         author_id\n0  paper1091      Makoto Satoh  Shinshu University  author2312688602\n1  paper1091     Ryo Muramatsu  Shinshu University  author2482909946\n2  paper1091      Mizue Kayama  Shinshu University  author2128134587\n3  paper1091     Kazunori Itoh  Shinshu University  author2101782692\n4  paper1091  Masami Hashimoto  Shinshu University  author2114054191",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>author_name</th>\n      <th>author_org</th>\n      <th>author_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>paper1091</td>\n      <td>Makoto Satoh</td>\n      <td>Shinshu University</td>\n      <td>author2312688602</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>paper1091</td>\n      <td>Ryo Muramatsu</td>\n      <td>Shinshu University</td>\n      <td>author2482909946</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>paper1091</td>\n      <td>Mizue Kayama</td>\n      <td>Shinshu University</td>\n      <td>author2128134587</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>paper1091</td>\n      <td>Kazunori Itoh</td>\n      <td>Shinshu University</td>\n      <td>author2101782692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>paper1091</td>\n      <td>Masami Hashimoto</td>\n      <td>Shinshu University</td>\n      <td>author2114054191</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f'output_entire_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_new = df[[\"id\",\"authors\"]]\n",
    "import ast\n",
    "df_new['authors'] = df_new['authors'].apply(ast.literal_eval)\n",
    "df_new = df_new.explode(\"authors\").reset_index(drop=True)\n",
    "\n",
    "def extract_values(row):\n",
    "    if \"org\" in row[\"authors\"]:\n",
    "        return pd.Series([row['authors']['name'], row['authors']['org'], row['authors']['id']])\n",
    "    else:\n",
    "        return pd.Series([row['authors']['name'], \"\", row['authors']['id']])\n",
    "    \n",
    "\n",
    "# Apply the function to create new columns\n",
    "df_new[['author_name', 'author_org', 'author_id']] = df_new.apply(lambda row: extract_values(row), axis=1)\n",
    "\n",
    "# Drop the original 'authors' column if needed\n",
    "df_new.drop('authors', axis=1, inplace=True)\n",
    "df_new[\"id\"]=\"paper\"+df_new[\"id\"].astype(str)\n",
    "df_new[\"author_id\"]=\"author\"+df_new[\"author_id\"].astype(str)\n",
    "print(df_new.shape)\n",
    "df_new.head()\n",
    "\n",
    "# save paper-author relationships\n",
    "# df_ = df_new[[\"id\",\"author_id\"]]\n",
    "# df_.to_csv(\"paper_author.csv\", index = False)\n",
    "\n",
    "# save author node attributes\n",
    "df_ = df_new[[\"author_id\",\"author_name\",\"author_org\"]]\n",
    "df_=df_.drop_duplicates(subset=['author_id'])\n",
    "print(df_.shape)\n",
    "df_.to_csv(\"authors.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T12:24:46.122895Z",
     "start_time": "2023-12-28T12:18:57.953878Z"
    }
   },
   "id": "ffa08e72b56cd415"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# paper_venue edge and venue node attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "779ddb90ed63099a"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['venue'] = df_new['venue'].apply(ast.literal_eval)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[['venue_name', 'venue_id', 'venue_type']] = df_new.apply(lambda row: extract_values(row), axis=1)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[['venue_name', 'venue_id', 'venue_type']] = df_new.apply(lambda row: extract_values(row), axis=1)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[['venue_name', 'venue_id', 'venue_type']] = df_new.apply(lambda row: extract_values(row), axis=1)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new.drop('venue', axis=1, inplace=True)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[\"id\"]=\"paper\"+df_new[\"id\"].astype(str)\n",
      "/var/folders/fs/r4jl6t2j2716kp94jc1zf4tc0000gn/T/ipykernel_79769/168251103.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new[\"venue_id\"]=\"venue\"+df_new[\"venue_id\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                         venue_name  \\\n",
      "0  paper1091  International Conference on Human-Computer Int...   \n",
      "1  paper1674        International Conference on Virtual Reality   \n",
      "2  paper1688       Pattern Recognition and Machine Intelligence   \n",
      "3  paper6522  International Symposium on Computer and Inform...   \n",
      "4  paper8373  Asian Conference on Intelligent Information an...   \n",
      "\n",
      "          venue_id venue_type  \n",
      "0  venue1127419992          C  \n",
      "1  venue2754954274          C  \n",
      "2  venue1136274694          C  \n",
      "3  venue1125967516          C  \n",
      "4  venue1123338449          C  \n",
      "(690779, 2)\n"
     ]
    }
   ],
   "source": [
    "file_path = f'output_entire_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_new = df[[\"id\",\"venue\"]]\n",
    "\n",
    "import ast\n",
    "df_new['venue'] = df_new['venue'].apply(ast.literal_eval)\n",
    "# df_new = df_new.explode(\"authors\")\n",
    "\n",
    "def extract_values(row):\n",
    "    # return pd.Series([row['venue']['raw'], row['venue']['id'], row['venue']['type']])\n",
    "    if row[\"venue\"][\"raw\"]==\"\":\n",
    "        return pd.Series([\"\", \"\", \"\"])\n",
    "    elif \"id\" not in row[\"venue\"]:\n",
    "        if \"type\" not in row[\"venue\"]:\n",
    "            return pd.Series([row['venue']['raw'], \"\", \"\"])\n",
    "        else:\n",
    "            return pd.Series([row['venue']['raw'], \"\", row['venue']['type']])\n",
    "    else:\n",
    "        return pd.Series([row['venue']['raw'], row['venue']['id'], row['venue']['type']])\n",
    "\n",
    "# Apply the function to create new columns\n",
    "df_new[['venue_name', 'venue_id', 'venue_type']] = df_new.apply(lambda row: extract_values(row), axis=1)\n",
    "\n",
    "# # Drop the original 'authors' column if needed\n",
    "df_new.drop('venue', axis=1, inplace=True)\n",
    "df_new[\"id\"]=\"paper\"+df_new[\"id\"].astype(str)\n",
    "df_new[\"venue_id\"]=\"venue\"+df_new[\"venue_id\"].astype(str)\n",
    "print(df_new.head())\n",
    "\n",
    "# paper_venue edges\n",
    "df_ = df_new[[\"id\",\"venue_id\"]]\n",
    "df_ = df_[df_.venue_id != \"venue\"]\n",
    "print(df_.shape)\n",
    "# df_ = df_new[[\"id\",\"venue_id\"]]\n",
    "df_.to_csv(\"paper_venue.csv\", index = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T02:12:27.495953Z",
     "start_time": "2023-12-29T02:10:18.994272Z"
    }
   },
   "id": "89d041196ed09a01"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691184, 3)\n",
      "(690779, 3)\n"
     ]
    }
   ],
   "source": [
    "df = df_new[[\"venue_id\",\"venue_name\",\"venue_type\"]]\n",
    "print(df.shape)\n",
    "df=df[df.venue_id!=\"venue\"]\n",
    "print(df.shape)\n",
    "df=df.drop_duplicates(subset=['venue_id'])\n",
    "df.to_csv(\"venues.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T02:15:17.971541Z",
     "start_time": "2023-12-29T02:15:17.760537Z"
    }
   },
   "id": "9c54e85ad9590765"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# paper_fos edge and fos node attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd82da209b990944"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "          id                    fos_name    fos_w fos_id\n0  paper1091  Telecommunications network  0.45139   fos0\n1  paper1091            Computer science  0.45245   fos1\n2  paper1091                    Mind map  0.53470   fos2\n3  paper1091  Human–computer interaction  0.47011   fos3\n4  paper1091                  Multimedia  0.46629   fos4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>fos_name</th>\n      <th>fos_w</th>\n      <th>fos_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>paper1091</td>\n      <td>Telecommunications network</td>\n      <td>0.45139</td>\n      <td>fos0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>paper1091</td>\n      <td>Computer science</td>\n      <td>0.45245</td>\n      <td>fos1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>paper1091</td>\n      <td>Mind map</td>\n      <td>0.53470</td>\n      <td>fos2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>paper1091</td>\n      <td>Human–computer interaction</td>\n      <td>0.47011</td>\n      <td>fos3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>paper1091</td>\n      <td>Multimedia</td>\n      <td>0.46629</td>\n      <td>fos4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = f'/home/ywang/GraphHT/datasets/DBLP-v5/output_entire_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_new = df[[\"id\",\"fos\"]]\n",
    "# df_new=df_new.iloc[:10000,:]\n",
    "print(df_new.shape)\n",
    "\n",
    "import ast\n",
    "\n",
    "df_new['fos'] = df_new['fos'].apply(ast.literal_eval)\n",
    "df_new = df_new.explode(\"fos\").reset_index(drop=True)\n",
    "\n",
    "def extract_values(row):\n",
    "    return pd.Series([row['fos']['name'], row['fos']['w']])\n",
    "\n",
    "\n",
    "# Apply the function to create new columns\n",
    "df_new[['fos_name', 'fos_w']] = df_new.apply(lambda row: extract_values(row), axis=1)\n",
    "\n",
    "# Drop the original 'authors' column if needed\n",
    "df_new.drop('fos', axis=1, inplace=True)\n",
    "df_new[\"id\"]=\"paper\"+df_new[\"id\"].astype(str)\n",
    "\n",
    "df_new[\"fos_id\"],_ = pd.factorize(df_new['fos_name'])\n",
    "df_new[\"fos_id\"]=\"fos\"+df_new[\"fos_id\"].astype(str)\n",
    "df_ = df_new[[\"id\",\"fos_id\",\"fos_w\"]]\n",
    "df_.to_csv(\"paper_fos.csv\", index = False)\n",
    "\n",
    "df_ = df_new[[\"fos_id\",\"fos_name\"]]\n",
    "df_ = df_.drop_duplicates(subset=['fos_id'])\n",
    "df_.to_csv(\"fos.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:12:02.023432Z",
     "start_time": "2023-12-29T03:11:37.548174Z"
    }
   },
   "id": "91a87c5471f6910"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-28T11:45:21.529130Z"
    }
   },
   "id": "33e3b3829665f2bf"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T14:26:58.055287Z",
     "start_time": "2024-01-03T14:26:58.048735Z"
    }
   },
   "id": "866322ffa2087d12"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T14:26:51.342100Z",
     "start_time": "2024-01-03T14:26:51.335808Z"
    }
   },
   "id": "3075bae0deea7c5a"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T14:26:49.525217Z",
     "start_time": "2024-01-03T14:26:49.517371Z"
    }
   },
   "id": "a72a22e96213b4e7"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T14:26:46.759194Z",
     "start_time": "2024-01-03T14:26:46.752058Z"
    }
   },
   "id": "b74bae7e1aaeeffb"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T14:26:43.821355Z",
     "start_time": "2024-01-03T14:26:43.820904Z"
    }
   },
   "id": "9cf9314b96d4a8ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
